{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Uczenie maszynowe polega na tworzeniu systemów zdolnych do uczenia się z danych. Przez „uczenie się” mamy na myśli uzyskiwanie coraz lepszych wyników w niektórych zadaniach przy uwzględnieniu określonej miary wydajności.\n",
    "\n",
    "2. Uczenie maszynowe nadaje się doskonale do złożonych problemów, dla których nie jesteśmy w stanie stworzyć algorytmicznego rozwiązania, do zastępowania długich list ręcznie dostrajanych reguł, do tworzenia systemów dostosowujących się do zmiennych środowisk, a także do pomagania w uczeniu ludzi (np. wydobywania danych).\n",
    "\n",
    "3. Oznakowanym zestawem danych uczących nazywamy zbiór danych zawierających oczekiwanerozwiązanie (etykietę) dla każdej próbki.\n",
    "\n",
    "4. Dwoma najpopularniejszymi rodzajami zadań nadzorowanych są regresja i klasyfikacja.\n",
    "\n",
    "5. Do popularnych zadań nienadzorowanych należą analiza skupień, wizualizacja, redukcja wymiarowości, a także uczenie przy użyciu reguł asocjacyjnych.\n",
    "\n",
    "6. Uczenie przez wzmacnianie jest najprawdopodobniej najlepszym wyborem, jeśli chcemy nauczyć robota poruszania się po różnych nieznanych terenach, ponieważ strategia ta jest przystosowana do rozwiązywania tego typu problemów. Możliwe jest wyrażenie takiego problemu w postaci zadania uczenia nienadzorowanego lub nadzorowanego, lecz byłoby ono mniej naturalne.\n",
    "\n",
    "7. Jeśli nie wiesz, w jaki sposób definiować grupy, możesz skorzystać z algorytmu analizy skupień (uczenie nienadzorowane) do rozdzielenia klientów na grupy według podobnych zainteresowań. Jeśli jednak wiesz, jakie grupy chcesz mieć, to możesz dostarczyć wiele przykładów z każdej takiej grupy do algorytmu klasyfikującego (uczenie nadzorowane), który rozmieści klientów w odpowiednich skupieniach.\n",
    "\n",
    "8. Wykrywanie spamu stanowi klasyczny problem uczenia nadzorowanego: dostarczamy algorytmowi wiele wiadomości e-mail wraz z etykietami (spam lub zwykła wiadomość).\n",
    "\n",
    "9. System uczenia przyrostowego, jak sama nazwa wskazuje, może uczyć się przyrostowo, w przeciwieństwie do systemu uczenia wsadowego. Dzięki temu jest on w stanie szybko dostosowywać się zarówno do zmieniających się danych, jak i systemów autonomicznych, a także potrafi uczyć się wobec bardzo dużych ilości danych.\n",
    "\n",
    "10. Algorytmy pozakorowe mogą obsługiwać olbrzymie ilości danych, które nie mieszczą się w głównej pamięci komputera. Algorytm uczenia pozakorowego rozdziela dane na minigrupy i do nauki z tych minigrup wykorzystuje techniki uczenia przyrostowego.\n",
    "\n",
    "11. System uczenia z przykładów uczy się dostarczanych przykładów „na pamięć”; następnie po dostarczeniu nowej próbki wykorzystuje miarę podobieństwa do wyszukania przypominających ją próbek uczących i za ich pomocą oblicza prognozę.\n",
    "\n",
    "12. Model zawiera przynajmniej jeden parametr określający prognozowany czynnik przy uwzględnieniu nowej próbki (np. nachylenie modelu liniowego). Algorytm uczący stara się znaleźć optymalne wartości tych parametrów, dzięki którym model będzie dobrze uogólniał wyniki dla nowych próbek. Hiperparametrem nazywamy parametr samego algorytmu uczącego, a nie modelu (np. stopień stosowanej regularyzacji).\n",
    "\n",
    "13. Algorytmy uczenia z modelu wyszukują optymalne wartości parametrów modelu, za pomocą których model ten będzie dobrze uogólniał wyniki do nowych próbek. Zazwyczaj uczymy takie systemy, minimalizując funkcję kosztu mierzącą błędy prognozowania systemu wobec zbioru uczącego, a także biorąc pod uwagę karę za złożoność modelu, jeśli jest on regularyzowany. W celu uzyskiwania prognoz dostarczamy cechy nowej próbki do funkcji predykcyjnej modelu, wykorzystując wartości parametrów określone przez algorytm uczący.\n",
    "\n",
    "14. Jednymi z głównych wyzwań w dziedzinie uczenia maszynowego są: brak danych, niska jakość danych, niereprezentatywne dane, nieprzydatne cechy, nadmiernie uproszczone modele ulegające niedotrenowaniu oraz nazbyt złożone modele mające tendencję do przetrenowania.\n",
    "\n",
    "15. Jeżeli model spisuje się świetnie wobec danych uczących, ale niezbyt dobrze generalizuje wyniki wobec nowych próbek, to najprawdopodobniej uległ przetrenowaniu (lub mieliśmy wyjątkowe szczęście w doborze zestawu uczącego). Możemy zmniejszyć stopień przetrenowania, dołączając więcej danych uczących, upraszczając model (poprzez wybór prostszego algorytmu, zmniejszenie liczby wykorzystywanych parametrów lub cech lub przeprowadzenie regularyzacji modelu) albo redukując zaszumienie danych uczących.\n",
    "\n",
    "16. Zestaw testowy służy do oszacowania błędu uogólniania, który model popełnia wobec nowych próbek, przed jego wprowadzeniem do środowiska produkcyjnego.\n",
    "\n",
    "17. Za pomocą zestawu walidacyjnego możemy porównywać modele. Umożliwia on wybór najlepszego modelu i dostrojenie hiperparametrów.\n",
    "\n",
    "18. Jeżeli dostroisz hiperparametry za pomocą zestawu testowego, ryzykujesz przetrenowanie modelu wobec niego, a wartość błędu uogólniania będzie optymistycznie mała (możesz wdrożyć model, który będzie sprawował się gorzej, niż się można było spodziewać).\n",
    "\n",
    "19. Sprawdzianem krzyżowym nazywamy technikę umożliwiającą porównywanie modeli (w celu doboru modelu i strojenia hiperparametrów) bez konieczności wydzielania zestawu walidacyjnego. Oszczędzasz w ten sposób cenne dane uczące."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
